============
IMPORTANT: The below will only work if the VCLUSTER is exposed using a public IP address

See a workaround (kind of) towards the bottom on this page
============


INSTALL VCLUSTER CLI
========================
>> curl -L -o vcluster "https://github.com/loft-sh/vcluster/releases/latest/download/vcluster-darwin-amd64" && sudo install -c -m 0755 vcluster /usr/local/bin && rm -f vcluster


INSTALL NGINX INGRESS CONTROLLER
=================================
[With --enable-ssl-passthrough=true flag set]

>> helm upgrade --install ingress-nginx ingress-nginx \
--repo https://kubernetes.github.io/ingress-nginx \
--namespace ingress-nginx --create-namespace \
--values nginx-ingress-helm-values.yaml


INSTALL A VCLUSTER USING HELM
==============================
>> helm repo add loft-sh https://charts.loft.sh

>> helm upgrade --install \
my-vcluster loft-sh/vcluster \
--namespace vcluster-my-vcluster \
--create-namespace \
--values vcluster-helm-values.yaml


CREATE AN INGRESS RESOURCE FOR CONNECTING TO VCLUSTER K8s CLUSTER
=====================================================================
>> k apply -f vcluster-ingress.yaml

>> k port-forward -n ingress-nginx svc/ingress-nginx-controller 9443:443


CREATE/GENERATE THE KUBECONFIG FILE TO CONNECT TO VCLUSTER K8s
=================================================================
>> vcluster connect my-vcluster -n vcluster-my-vcluster --update-current=false --server=my-vcluster.127.0.0.1.nip.io:9443

A file called "kubeconfig.yaml" will be created in the working dir.


ACCESS/CONNECT/USE VCLUSTER K8s
=================================
k get all -A --kubeconfig ./kubeconfig.yaml


REGISTER OUR VCLUSTER K8s WITH ArgoCD
=========================================
>> k config get-contexts --kubeconfig ./kubeconfig.yaml
Get the name of the kubeconfig contex that will be registered to ArgoCD

>> argocd cluster add vcluster_my-vcluster_vcluster-my-vcluster_k3d-mycluster --kubeconfig ./kubeconfig.yaml -y --upsert

NOTE: The above does not work and we see the following error:
---
INFO[0000] ServiceAccount "argocd-manager" already exists in namespace "kube-system"
INFO[0000] ClusterRole "argocd-manager-role" updated
INFO[0000] ClusterRoleBinding "argocd-manager-role-binding" updated
FATA[0000] rpc error: code = Unknown desc = Get "https://my-vcluster.127.0.0.1.nip.io:9443/version?timeout=32s": dial tcp 127.0.0.1:9443: connect: connection refused
---
The error is from the Argocd controller. It is unable to connect to my-vcluster.127.0.0.1.nip.io:9443 from within the cluster.
This is a valid error as my-vcluster.127.0.0.1.nip.io is accessible from ourside the K8s cluster and only on my MacBook.


HACK: 
    Adding the "in-cluster" (the K8s cluster that ArgoCD is running in) with a different name to simulate the registration of a 
    new cluster to ArgoCD

>> argocd cluster add vcluster_my-vcluster_vcluster-my-vcluster_k3d-mycluster --kubeconfig ./kubeconfig.yaml --in-cluster -y --upsert

Note the "--in-cluster" option.

